package loop

import (
	"context"
	"encoding/json"
	"os"
	"path/filepath"
	"testing"
	"time"

	"github.com/minicodemonkey/chief/internal/prd"
)

// createMockClaudeScript creates a shell script that outputs predefined stream-json.
func createMockClaudeScript(t *testing.T, dir string, output []string) string {
	t.Helper()

	scriptPath := filepath.Join(dir, "mock-claude")
	content := "#!/bin/bash\n"
	for _, line := range output {
		content += "echo '" + line + "'\n"
	}

	if err := os.WriteFile(scriptPath, []byte(content), 0755); err != nil {
		t.Fatalf("Failed to create mock script: %v", err)
	}

	return scriptPath
}

// createTestPRD creates a minimal test PRD file.
func createTestPRD(t *testing.T, dir string, allComplete bool) string {
	t.Helper()

	prdFile := &prd.PRD{
		Project:     "Test Project",
		Description: "Test Description",
		UserStories: []prd.UserStory{
			{
				ID:          "US-001",
				Title:       "Test Story",
				Description: "A test story",
				Priority:    1,
				Passes:      allComplete,
			},
		},
	}

	prdPath := filepath.Join(dir, "prd.json")
	data, _ := json.MarshalIndent(prdFile, "", "  ")
	if err := os.WriteFile(prdPath, data, 0644); err != nil {
		t.Fatalf("Failed to create test PRD: %v", err)
	}

	return prdPath
}

func TestNewLoop(t *testing.T) {
	l := NewLoop("/path/to/prd.json", "test prompt", 5)

	if l.prdPath != "/path/to/prd.json" {
		t.Errorf("Expected prdPath %q, got %q", "/path/to/prd.json", l.prdPath)
	}
	if l.prompt != "test prompt" {
		t.Errorf("Expected prompt %q, got %q", "test prompt", l.prompt)
	}
	if l.maxIter != 5 {
		t.Errorf("Expected maxIter %d, got %d", 5, l.maxIter)
	}
	if l.events == nil {
		t.Error("Expected events channel to be initialized")
	}
}

func TestNewLoopWithWorkDir(t *testing.T) {
	l := NewLoopWithWorkDir("/path/to/prd.json", "/work/dir", "test prompt", 5)

	if l.prdPath != "/path/to/prd.json" {
		t.Errorf("Expected prdPath %q, got %q", "/path/to/prd.json", l.prdPath)
	}
	if l.workDir != "/work/dir" {
		t.Errorf("Expected workDir %q, got %q", "/work/dir", l.workDir)
	}
	if l.prompt != "test prompt" {
		t.Errorf("Expected prompt %q, got %q", "test prompt", l.prompt)
	}
	if l.maxIter != 5 {
		t.Errorf("Expected maxIter %d, got %d", 5, l.maxIter)
	}
	if l.events == nil {
		t.Error("Expected events channel to be initialized")
	}
}

func TestNewLoopWithWorkDir_EmptyWorkDir(t *testing.T) {
	l := NewLoopWithWorkDir("/path/to/prd.json", "", "test prompt", 5)

	if l.workDir != "" {
		t.Errorf("Expected empty workDir, got %q", l.workDir)
	}
}

func TestLoop_Events(t *testing.T) {
	l := NewLoop("/path/to/prd.json", "test prompt", 5)
	events := l.Events()

	if events == nil {
		t.Error("Expected Events() to return a channel")
	}
}

func TestLoop_Iteration(t *testing.T) {
	l := NewLoop("/path/to/prd.json", "test prompt", 5)

	if l.Iteration() != 0 {
		t.Errorf("Expected initial iteration to be 0, got %d", l.Iteration())
	}

	l.iteration = 3
	if l.Iteration() != 3 {
		t.Errorf("Expected iteration to be 3, got %d", l.Iteration())
	}
}

func TestLoop_Stop(t *testing.T) {
	l := NewLoop("/path/to/prd.json", "test prompt", 5)

	l.Stop()

	l.mu.Lock()
	stopped := l.stopped
	l.mu.Unlock()

	if !stopped {
		t.Error("Expected loop to be marked as stopped")
	}
}

// TestLoop_RunWithMockClaude tests the loop with a mock Claude script.
// This is an integration test that requires a Unix-like shell.
func TestLoop_RunWithMockClaude(t *testing.T) {
	if os.Getenv("CI") != "" {
		t.Skip("Skipping integration test in CI")
	}

	tmpDir := t.TempDir()

	// Create a mock Claude output
	mockOutput := []string{
		`{"type":"system","subtype":"init"}`,
		`{"type":"assistant","message":{"content":[{"type":"text","text":"Starting work on story"}]}}`,
		`{"type":"assistant","message":{"content":[{"type":"tool_use","id":"123","name":"Read","input":{"file_path":"test.go"}}]}}`,
		`{"type":"user","message":{"content":[{"type":"tool_result","tool_use_id":"123","content":"file content"}]}}`,
		`{"type":"assistant","message":{"content":[{"type":"text","text":"Work complete"}]}}`,
	}

	scriptPath := createMockClaudeScript(t, tmpDir, mockOutput)
	prdPath := createTestPRD(t, tmpDir, true) // Already complete so loop stops after one iteration

	// Create a prompt that invokes our mock script instead of real Claude
	// For the actual test, we'll test the internal methods
	l := NewLoop(prdPath, "test prompt", 1)

	// Override the command for testing - we'll test processOutput directly
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	// Collect events in a goroutine
	var events []Event
	done := make(chan bool)
	go func() {
		for event := range l.Events() {
			events = append(events, event)
		}
		done <- true
	}()

	// Test processOutput directly with mock data
	r, w, _ := os.Pipe()
	go func() {
		for _, line := range mockOutput {
			w.WriteString(line + "\n")
		}
		w.Close()
	}()

	l.iteration = 1
	l.processOutput(r)

	// Close events channel and wait for collection
	close(l.events)
	<-done

	// Verify we got expected events
	if len(events) == 0 {
		t.Error("Expected at least one event")
	}

	// Check that we got the expected event types
	hasIterationStart := false
	hasAssistantText := false
	hasToolStart := false
	hasToolResult := false

	for _, e := range events {
		switch e.Type {
		case EventIterationStart:
			hasIterationStart = true
		case EventAssistantText:
			hasAssistantText = true
		case EventToolStart:
			hasToolStart = true
			if e.Tool != "Read" {
				t.Errorf("Expected tool name 'Read', got %q", e.Tool)
			}
		case EventToolResult:
			hasToolResult = true
		}
	}

	if !hasIterationStart {
		t.Error("Expected IterationStart event")
	}
	if !hasAssistantText {
		t.Error("Expected AssistantText event")
	}
	if !hasToolStart {
		t.Error("Expected ToolStart event")
	}
	if !hasToolResult {
		t.Error("Expected ToolResult event")
	}

	// Cleanup
	_ = scriptPath // Avoid unused variable warning
	_ = ctx        // Context used for reference
}

// TestLoop_MaxIterations tests that the loop stops after max iterations.
func TestLoop_MaxIterations(t *testing.T) {
	tmpDir := t.TempDir()
	prdPath := createTestPRD(t, tmpDir, false) // Not complete

	l := NewLoop(prdPath, "test prompt", 2)

	// Simulate reaching max iterations by manually incrementing
	l.iteration = 2

	// The Run method should check and emit MaxIterationsReached
	// For this test, we verify the check logic
	if l.iteration >= l.maxIter {
		l.events <- Event{
			Type:      EventMaxIterationsReached,
			Iteration: l.iteration,
		}
	}

	event := <-l.events
	if event.Type != EventMaxIterationsReached {
		t.Errorf("Expected MaxIterationsReached event, got %v", event.Type)
	}
}

// TestLoop_CompleteDetection tests that the loop detects completion.
func TestLoop_CompleteDetection(t *testing.T) {
	tmpDir := t.TempDir()
	prdPath := createTestPRD(t, tmpDir, true) // All complete

	p, err := prd.LoadPRD(prdPath)
	if err != nil {
		t.Fatalf("Failed to load PRD: %v", err)
	}

	if !p.AllComplete() {
		t.Error("Expected PRD to be all complete")
	}
}

// TestLoop_LogFile tests that log file is created and written to.
func TestLoop_LogFile(t *testing.T) {
	tmpDir := t.TempDir()
	_ = createTestPRD(t, tmpDir, true)

	logPath := filepath.Join(tmpDir, "claude.log")
	logFile, err := os.OpenFile(logPath, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
	if err != nil {
		t.Fatalf("Failed to create log file: %v", err)
	}

	l := NewLoop(filepath.Join(tmpDir, "prd.json"), "test", 1)
	l.logFile = logFile

	l.logLine("test log line")
	logFile.Close()

	// Read back the log file
	data, err := os.ReadFile(logPath)
	if err != nil {
		t.Fatalf("Failed to read log file: %v", err)
	}

	if string(data) != "test log line\n" {
		t.Errorf("Expected log line content, got %q", string(data))
	}
}

// TestLoop_ChiefCompleteEvent tests detection of <chief-complete/> event.
func TestLoop_ChiefCompleteEvent(t *testing.T) {
	l := NewLoop("/test/prd.json", "test", 5)
	l.iteration = 1

	done := make(chan bool)
	var events []Event
	go func() {
		for event := range l.Events() {
			events = append(events, event)
			if event.Type == EventComplete {
				break
			}
		}
		done <- true
	}()

	// Simulate processing a line with chief-complete
	r, w, _ := os.Pipe()
	go func() {
		w.WriteString(`{"type":"assistant","message":{"content":[{"type":"text","text":"All done! <chief-complete/>"}]}}` + "\n")
		w.Close()
	}()

	l.processOutput(r)
	close(l.events)
	<-done

	// Check that we got a Complete event
	hasComplete := false
	for _, e := range events {
		if e.Type == EventComplete {
			hasComplete = true
		}
	}

	if !hasComplete {
		t.Error("Expected Complete event for <chief-complete/>")
	}
}

// TestLoop_SetMaxIterations tests setting max iterations at runtime.
func TestLoop_SetMaxIterations(t *testing.T) {
	l := NewLoop("/test/prd.json", "test", 5)

	if l.MaxIterations() != 5 {
		t.Errorf("Expected initial maxIter 5, got %d", l.MaxIterations())
	}

	l.SetMaxIterations(10)

	if l.MaxIterations() != 10 {
		t.Errorf("Expected maxIter 10 after set, got %d", l.MaxIterations())
	}
}

// TestDefaultRetryConfig tests the default retry configuration.
func TestDefaultRetryConfig(t *testing.T) {
	config := DefaultRetryConfig()

	if config.MaxRetries != 3 {
		t.Errorf("Expected MaxRetries 3, got %d", config.MaxRetries)
	}
	if !config.Enabled {
		t.Error("Expected Enabled to be true")
	}
	if len(config.RetryDelays) != 3 {
		t.Errorf("Expected 3 retry delays, got %d", len(config.RetryDelays))
	}
}

// TestLoop_SetRetryConfig tests setting retry config.
func TestLoop_SetRetryConfig(t *testing.T) {
	l := NewLoop("/test/prd.json", "test", 5)

	// Check default
	if !l.retryConfig.Enabled {
		t.Error("Expected default retry to be enabled")
	}

	// Disable retry
	l.DisableRetry()
	if l.retryConfig.Enabled {
		t.Error("Expected retry to be disabled after DisableRetry()")
	}

	// Set custom config
	customConfig := RetryConfig{
		MaxRetries:  5,
		RetryDelays: []time.Duration{time.Second},
		Enabled:     true,
	}
	l.SetRetryConfig(customConfig)

	if l.retryConfig.MaxRetries != 5 {
		t.Errorf("Expected MaxRetries 5, got %d", l.retryConfig.MaxRetries)
	}
}
